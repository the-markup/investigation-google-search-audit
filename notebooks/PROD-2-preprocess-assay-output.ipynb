{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "This notebook analyses the results of the element categorization and area estimations from the last notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We preprocess the contents of each of these json files by:\n",
    "1. Normalizing the length of the page, and calculating the area of each element, <br>\n",
    "   - in N-quantiles.\n",
    "   - in the top 15% of the page.\n",
    "   - in in the full page.\n",
    "2. Standardizing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import gzip\n",
    "import time\n",
    "import glob\n",
    "import tempfile\n",
    "import warnings\n",
    "import inspect\n",
    "from collections import Counter\n",
    "from multiprocessing import Pool\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from utils.config import (\n",
    "    google_domains,\n",
    "    cat2color,\n",
    ")\n",
    "\n",
    "from utils.web_assay import calc_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the intermediates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the page into how many equal segments?\n",
    "n_quantiles = 50\n",
    "\n",
    "# height of Google search bar and tabs in pixels\n",
    "header = 160\n",
    "\n",
    "# width of the emulator viewport in pixels\n",
    "viewport_width = 363\n",
    "\n",
    "# variables\n",
    "subsample = True\n",
    "data_dir = '../data' if not subsample else '../data_subsample'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "data_dir_metadata = f'{data_dir}/intermediary/google_search/'\n",
    "metadata_pattern = os.path.join(data_dir_metadata, \n",
    "                                'iPhone-X/*/*/*/*/json/parsed_meta.jsonl')\n",
    "# output\n",
    "fn_metadata = f'{data_dir}/intermediary/element_metadata.jsonl.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_files = glob.glob(metadata_pattern)\n",
    "len(metadata_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Page Normalization and Calculating Area\n",
    "We read each metadata_file, and perform some calculations to get area in `read_file`.\n",
    "We use `Pool` to distribute this function across `n_processes` to speed things up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bottom(row):\n",
    "    \"\"\"Finds the bottom of the last element\"\"\"\n",
    "    return row['location']['y'] + row['dimensions']['height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(fn):\n",
    "    \"\"\"A json reader, this function allows parallelization\"\"\"\n",
    "    metadata = pd.read_json(fn, lines=True, \n",
    "                            orient='records')\n",
    "    \n",
    "    bottom_element = metadata.apply(get_bottom, \n",
    "                                    axis=1).max()\n",
    "    metadata.loc[:, \"position_last_element\"] = bottom_element\n",
    "    metadata.loc[:, \"fn_metadata\"] = fn\n",
    "    \n",
    "    # how long is each quartile?\n",
    "    interval = (bottom_element - header) / n_quantiles\n",
    "    \n",
    "    # what is the boundary of the top of a page?\n",
    "    above_the_fold = ((bottom_element - header) * .15) + header\n",
    "    \n",
    "    # create boundaries for N equal-sized sections in the search result\n",
    "    quantiles = {}\n",
    "    for i in range(n_quantiles):\n",
    "        upper = (i * interval) + header\n",
    "        lower = ((i + 1) * interval) + header\n",
    "        \n",
    "        quantiles[f'q{i + 1}'] = {\n",
    "            'upper_bound' : upper,\n",
    "            'lower_bound' : lower\n",
    "        }\n",
    "\n",
    "    # calculate the area of each element in each section.\n",
    "    for k, v in quantiles.items():\n",
    "        metadata.loc[:, f\"{k}_area\"] = metadata.apply(\n",
    "            lambda row: calc_area(\n",
    "                rect= row['dimensions'],\n",
    "                location= row['location'],\n",
    "                width= viewport_width,\n",
    "                height_top= v['upper_bound'],\n",
    "                height_bottom= v['lower_bound']\n",
    "            ), axis=1\n",
    "        )\n",
    "    \n",
    "    # calculate the area of each element in the entire search result\n",
    "    metadata.loc[:, \"area_page\"] = metadata.apply(\n",
    "        lambda row: calc_area(\n",
    "            rect= row['dimensions'],\n",
    "            location= row['location'],\n",
    "            width= viewport_width,\n",
    "        ), axis=1\n",
    "    )\n",
    "    \n",
    "    # calculate the area of the \"top of the page\"\n",
    "    metadata.loc[:, \"area_above_the_fold\"] = metadata.apply(\n",
    "        lambda row: calc_area(\n",
    "            rect= row['dimensions'],\n",
    "            location= row['location'],\n",
    "            width= viewport_width,\n",
    "            height_bottom = above_the_fold\n",
    "        ), axis=1\n",
    "    )\n",
    "    \n",
    "    for col in ['area', 'element', 'element_class']:\n",
    "        metadata.pop(col)\n",
    "        \n",
    "    return metadata.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:27<00:00, 14.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# how many cores to use when reading and processing files\n",
    "n_processes = 12\n",
    "\n",
    "data = []\n",
    "with Pool(n_processes) as pool:\n",
    "    for record in tqdm(pool.imap_unordered(read_file, metadata_files), \n",
    "                       total=len(metadata_files)):\n",
    "        data.extend(record)\n",
    "        \n",
    "# put the contents into Pandas\n",
    "df = pd.DataFrame(data)\n",
    "del data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse categorization from labels\n",
    "We need to do some extra column manipulations here, as the parsers in the previous notebook return over 68 different labels for stuff we'd find on the search page.\n",
    "\n",
    "These labels are hyphen-delimited, with the first word representing one of our five categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_data(category : str):\n",
    "    \"\"\"Thae label is the first word of each category\"\"\"\n",
    "    label = category.split('-')[0]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df.category.apply(label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "link       16606\n",
       "answer      5955\n",
       "organic     5793\n",
       "amp         2221\n",
       "ads          149\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our methods paper<br>\n",
    "link is called \"Google Products\"<br>\n",
    "answer is called \"Google Answers\"<br>\n",
    "organic is called \"Non-Google\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30724"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing labels\n",
    "Here we combine and rename labels to be more legible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat2catstd = {\n",
    "    'organic-search_result_1a' : 'organic-search_result',\n",
    "    'organic-search_result_2a' : 'organic-search_result',\n",
    "    'organic-search_result_2c': 'organic-search_result',\n",
    "    'organic-search_result_1b' : 'organic-search_result',\n",
    "    'organic-search_result_2b': 'organic-search_result',\n",
    "    'amp-search_result_2' : 'amp-search_result',\n",
    "    'amp-search_result_1' : 'amp-search_result',\n",
    "    'amp-search_result_3': 'amp-search_result',\n",
    "    'organic-tweet_2 ': 'organic-tweet',\n",
    "    'answer-expand_1' : 'answer-expand',\n",
    "    'answer-expand_2' :'answer-expand',\n",
    "    'answer-expand_3' :'answer-expand',\n",
    "    'link-google_2' : 'link-google',\n",
    "    'organic-tweet_2' : 'organic-tweet',\n",
    "    'link-button_2' : 'link-button',\n",
    "    'answer-knowledge_panel_answer_1' : 'answer-knowledge_panel_answer',\n",
    "    'answer-knowledge_panel_answer_2' : 'answer-knowledge_panel_answer',\n",
    "    'answer-date_2' : 'answer-date',\n",
    "    'link-youtube_search_result_1a' : 'link-youtube_search_result',\n",
    "    'link-youtube_search_result_2a' : 'link-youtube_search_result',\n",
    "    'link-youtube_search_result_2b' : 'link-youtube_search_result',\n",
    "    'link-flights_1' : 'link-flights',\n",
    "    'link-google_map_2' : 'link-google_map'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.category.replace(cat2catstd, \n",
    "                    inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "link2subcat = {\n",
    "    'link-site_search' : 'google-search',\n",
    "    'link-movie_trailer' : 'google-video',\n",
    "    'link-video_top_answer' : 'google-video',\n",
    "    'link-local_google_maps_results' : 'google-maps',\n",
    "    'link-google_map' : 'google-maps',\n",
    "    'link-img_reverse' : 'google-images',\n",
    "    'link-knowledge_panel_tab' : 'google-knowledge-panel-links',\n",
    "    'link-knowledge_panel_title' : 'google-knowledge-panel-links',\n",
    "    'link-youtube' : 'google-video'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_category(row):\n",
    "    '''Logic to assign a standardized category'''\n",
    "    category = row['category']\n",
    "    label = row['label']\n",
    "    \n",
    "    if label == 'amp':\n",
    "        subcat = category\n",
    "    elif label == 'link':\n",
    "        subcat = link2subcat.get(category, 'google-misc')\n",
    "    elif label == 'answer':\n",
    "        if 'expand' in category:\n",
    "            subcat = 'google-expandable-answer'\n",
    "        else:\n",
    "            subcat = 'google-answer'\n",
    "    elif label == 'organic':\n",
    "        subcat = category if category != 'organic-tweet' else 'organic'\n",
    "    if label in ['ads']:\n",
    "        subcat = label\n",
    "    return subcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category_standard'] = df.apply(standardize_category, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make these google search\n",
    "df.loc[(df.link.str[:9] == '/search?q') &\n",
    "       (df.label == 'link'), \n",
    "       'category_standard'] = 'google-search'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we attribute some temporal metadata..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When was the data processed and collected?\n",
    "df.loc[:, \"date_parsed\"] = pd.datetime.now().strftime('%Y-%m-%d')\n",
    "df.loc[:, \"date_collected\"] = df.fn_input.apply(\n",
    "    lambda x: '-'.join(x.split('iPhone-X/')[-1].split('/')[:3])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"HoopsHype \\u203a tag \\u203a tom-thibodeauTom Thibodeau Rumors | HoopsHypeYou last coached a game on Jan. 6, 2019. What have you've been doing to stay busy during the last 11 months? Tom Thibodeau: \\u201cI've been\\u00a0...\",\n",
      "  \"link\": \"https://hoopshype.com/tag/tom-thibodeau/\",\n",
      "  \"domain\": \"hoopshype.com\",\n",
      "  \"xpath\": \"/html/body/div[10]/div/div[6]/div/div[3]/div/div/div/sticky-header/div[2]/div/g-flippy-carousel/div/div/ol/li[1]/span/div/div/div[1]/div[3]/div[9]/div[2]/div[6]/div/div\",\n",
      "  \"category\": \"organic-search_result\",\n",
      "  \"tag\": \"div\",\n",
      "  \"attrs\": {\n",
      "    \"class\": [\n",
      "      \"mnr-c\",\n",
      "      \"xpd\",\n",
      "      \"O9g5cc\",\n",
      "      \"uUPGi\"\n",
      "    ]\n",
      "  },\n",
      "  \"dimensions\": {\n",
      "    \"height\": 197.0,\n",
      "    \"width\": 347.0\n",
      "  },\n",
      "  \"location\": {\n",
      "    \"x\": 8,\n",
      "    \"y\": 4555\n",
      "  },\n",
      "  \"area_page\": 68359.0,\n",
      "  \"fn_input\": \"../data/input/google_search/iPhone-X/2020/01/02/Tom-Thibodeau/html/webpage_raw.html\",\n",
      "  \"position_last_element\": 5492.0,\n",
      "  \"fn_metadata\": \"../data_subsample/intermediary/google_search/iPhone-X/2020/01/02/Tom-Thibodeau/json/parsed_meta.jsonl\",\n",
      "  \"q1_area\": 0.0,\n",
      "  \"q2_area\": 0.0,\n",
      "  \"q3_area\": 0.0,\n",
      "  \"q4_area\": 0.0,\n",
      "  \"q5_area\": 0.0,\n",
      "  \"q6_area\": 0.0,\n",
      "  \"q7_area\": 0.0,\n",
      "  \"q8_area\": 0.0,\n",
      "  \"q9_area\": 0.0,\n",
      "  \"q10_area\": 0.0,\n",
      "  \"q11_area\": 0.0,\n",
      "  \"q12_area\": 0.0,\n",
      "  \"q13_area\": 0.0,\n",
      "  \"q14_area\": 0.0,\n",
      "  \"q15_area\": 0.0,\n",
      "  \"q16_area\": 0.0,\n",
      "  \"q17_area\": 0.0,\n",
      "  \"q18_area\": 0.0,\n",
      "  \"q19_area\": 0.0,\n",
      "  \"q20_area\": 0.0,\n",
      "  \"q21_area\": 0.0,\n",
      "  \"q22_area\": 0.0,\n",
      "  \"q23_area\": 0.0,\n",
      "  \"q24_area\": 0.0,\n",
      "  \"q25_area\": 0.0,\n",
      "  \"q26_area\": 0.0,\n",
      "  \"q27_area\": 0.0,\n",
      "  \"q28_area\": 0.0,\n",
      "  \"q29_area\": 0.0,\n",
      "  \"q30_area\": 0.0,\n",
      "  \"q31_area\": 0.0,\n",
      "  \"q32_area\": 0.0,\n",
      "  \"q33_area\": 0.0,\n",
      "  \"q34_area\": 0.0,\n",
      "  \"q35_area\": 0.0,\n",
      "  \"q36_area\": 0.0,\n",
      "  \"q37_area\": 0.0,\n",
      "  \"q38_area\": 0.0,\n",
      "  \"q39_area\": 0.0,\n",
      "  \"q40_area\": 0.0,\n",
      "  \"q41_area\": 0.0,\n",
      "  \"q42_area\": 29106.360000000037,\n",
      "  \"q43_area\": 37004.08000000011,\n",
      "  \"q44_area\": 2248.5599999998485,\n",
      "  \"q45_area\": 0.0,\n",
      "  \"q46_area\": 0.0,\n",
      "  \"q47_area\": 0.0,\n",
      "  \"q48_area\": 0.0,\n",
      "  \"q49_area\": 0.0,\n",
      "  \"q50_area\": 0.0,\n",
      "  \"area_above_the_fold\": 0.0,\n",
      "  \"label\": \"organic\",\n",
      "  \"category_standard\": \"organic-search_result\",\n",
      "  \"date_parsed\": \"2020-06-13\",\n",
      "  \"date_collected\": \"2020-01-02\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# What does a record look like?\n",
    "print(json.dumps(df.iloc[-1].to_dict(), \n",
    "                 indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to JSON\n",
    "With the data pre-processed, we want to save the records for analysis.\n",
    "\n",
    "Normally, something like:<br>\n",
    "```\n",
    "df.to_json(fn_metadata, compression='gzip', \n",
    "           lines=True, orient='records')\n",
    "```\n",
    "\n",
    "...would be sufficient. \n",
    "\n",
    "However, doing so can often crash notebooks when working with a large dataframe.\n",
    "\n",
    "Instead, we will use reliable default libraries like gzip and json to write a new-line delimited json file one record at at time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30724/30724 [00:01<00:00, 17355.13it/s]\n"
     ]
    }
   ],
   "source": [
    "with gzip.open(fn_metadata, 'wb') as f:\n",
    "    for row in tqdm(df.to_dict(orient='records')):\n",
    "        record = json.dumps(row) + '\\n'\n",
    "        record = record.encode('utf-8')\n",
    "        f.write(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics of page length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "652"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height - header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = df.drop_duplicates(subset='fn_input').position_last_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     400.000000\n",
       "mean     4946.667500\n",
       "std      1020.441551\n",
       "min      2265.000000\n",
       "25%      4191.500000\n",
       "50%      4934.500000\n",
       "75%      5683.750000\n",
       "max      7752.000000\n",
       "Name: position_last_element, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lengths - header).describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
